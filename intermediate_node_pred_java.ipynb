{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98625ebe-a7ba-4037-be77-b38cdce9e145",
   "metadata": {},
   "source": [
    "# Experiment for RQ2: Intermediate node prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd54b7c-1344-42cb-9ea5-c1ff3648859e",
   "metadata": {},
   "source": [
    "### We first build the dataset for intermediate node prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6353f7b2-c411-4fbc-ace9-f37f9da4a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import load_vocab\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "from py_config_runner import ConfigObject\n",
    "from module import FastASTTrans\n",
    "from ignite.utils import convert_tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586a27f9-a281-42a2-8264-10b121e06860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a773de23b2842dd93557447ebce74df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrices_path = './csa-trans/processed/tree_sitter_java/test/split_matrices.npz'\n",
    "data = np.load(matrices_path, allow_pickle=True)\n",
    "test_rfs = data[\"root_first_seq\"]\n",
    "\n",
    "for split_idx, rfs in enumerate([test_rfs]):\n",
    "    original_test_dataset = {}\n",
    "    for data_idx, sample_ast in enumerate(tqdm(rfs)):\n",
    "        # generate parent_path_list and brother_path_list\n",
    "        distance_map = {}\n",
    "        brother_map = {}\n",
    "\n",
    "        parent_path_list = []\n",
    "        brother_path_list = []\n",
    "\n",
    "        for node in sample_ast:\n",
    "            if len(node.children) == 0:\n",
    "                path = [node.label]\n",
    "                n = node\n",
    "                while n.parent is not None:\n",
    "                    path.append(n.parent.label)\n",
    "                    n = n.parent\n",
    "                parent_path_list.append(list(reversed(path)))\n",
    "            else:\n",
    "                brother_path_list.append([child.label for child in node.children])\n",
    "\n",
    "        # remove identifier dangling nodes from parent path\n",
    "        refined_parent_path_list = []\n",
    "        for path in parent_path_list:\n",
    "            idt_remove_path = []\n",
    "            for e in path:\n",
    "                if e.split(':')[0] != 'idt':\n",
    "                    idt_remove_path.append(e)\n",
    "                else:\n",
    "                    break\n",
    "            if len(idt_remove_path) < 2:\n",
    "                continue\n",
    "            refined_parent_path_list.append(idt_remove_path)\n",
    "\n",
    "        # remove identifier nodes from brother list\n",
    "        refined_brother_path_list = []\n",
    "        for path in brother_path_list:\n",
    "            idt_remove_path = []\n",
    "            for e in path:\n",
    "                if e.split(':')[0] != 'idt':\n",
    "                    idt_remove_path.append(e)\n",
    "            refined_brother_path_list.append(idt_remove_path)\n",
    "\n",
    "        # get dataset\n",
    "        parent_intermediate = set()\n",
    "        brother_intermediate = set()\n",
    "        for par_path in refined_parent_path_list:\n",
    "            for idx in range(len(par_path) - 2):\n",
    "                prev = par_path[idx]\n",
    "                inter = par_path[idx + 1]\n",
    "                after = par_path[idx + 2]\n",
    "                parent_intermediate.add((prev, inter, after))\n",
    "\n",
    "        for bro_path in refined_brother_path_list:\n",
    "            for e in combinations(bro_path, 2):\n",
    "                parent = sample_ast[int(e[0].split(':')[-1]) -1].parent\n",
    "                brother_intermediate.add((e[0], parent.label, e[1]))\n",
    "\n",
    "        parent_intermediate = list(parent_intermediate)\n",
    "        brother_intermediate = list(brother_intermediate)\n",
    "        # sample\n",
    "        SAMPLE_NUM = min([10, len(parent_intermediate), len(brother_intermediate)])\n",
    "        idx1 = np.random.choice(range(len(parent_intermediate)), size=SAMPLE_NUM, replace=False)\n",
    "        idx2 = np.random.choice(range(len(brother_intermediate)), size=SAMPLE_NUM, replace=False)\n",
    "        parent_inter = [parent_intermediate[i] for i in idx1]\n",
    "        brother_inter = [brother_intermediate[i] for i in idx2]\n",
    "        original_test_dataset[data_idx] = parent_inter + brother_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9a8f46-94b0-45f6-842a-c7fd16112fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _graph_prepare_batch(batch, device=None, non_blocking: bool = False):\n",
    "    x, y = batch\n",
    "    return (\n",
    "        x.to(device),\n",
    "        convert_tensor(y, device=device, non_blocking=non_blocking),\n",
    "    )\n",
    "\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, embeddings, targets):\n",
    "        self.x = embeddings\n",
    "        self.y = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        return x, y\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, indim, hidden, outdim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(indim, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, hidden)\n",
    "        self.fc4 = nn.Linear(hidden, outdim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b241d-330e-48c9-b97a-81dc7261a76b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Node prediction for CSA-Trans on Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ed41a6-9bfe-417e-9099-10e09f40c11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set Name : < Fast AST Data Set >\n",
      "loading test data...\n",
      "loading existing dataset\n",
      "dataset lenght: 8714\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"Example application\")\n",
    "parser.add_argument(\"--config\", type=Path, help=\"Input configuration file\")\n",
    "parser.add_argument(\"--use_hype_params\", action=\"store_true\")\n",
    "parser.add_argument(\"--data_type\", type=str, default=\"\")\n",
    "parser.add_argument(\"--exp_type\", type=str, default=\"summary\")\n",
    "parser.add_argument(\"--g\", type=str, default=\"\")\n",
    "\n",
    "args = parser.parse_args(['--config', './config/java.py', '--g', '0',])\n",
    "config = ConfigObject(args.config)\n",
    "\n",
    "if args.g != \"\":\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.g\n",
    "    config.device = \"cuda\"\n",
    "    config.g = args.g\n",
    "\n",
    "(config.src_vocab,config.tgt_vocab,) = load_vocab(config.data_dir, config.is_split, config.data_type)\n",
    "test_data_set = config.data_set(config, \"test\")\n",
    "test_loader = DataLoader(dataset=test_data_set,batch_size=config.batch_size // len(config.g.split(\",\")),shuffle=False,collate_fn=test_data_set.collect_fn,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fdbba64-e33b-488c-8f67-7296cf27d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbm_param: 14789888\n",
      "decoder param: 16817152\n",
      "generator param: 10260000\n",
      "Init or load model.\n"
     ]
    }
   ],
   "source": [
    "model = config.model(\n",
    "    config.src_vocab.size(),\n",
    "    config.tgt_vocab.size(),\n",
    "    config.hidden_size,\n",
    "    config.num_heads,\n",
    "    config.num_layers,\n",
    "    config.sbm_layers,\n",
    "    config.use_pegen,\n",
    "    config.dim_feed_forward,\n",
    "    config.dropout,\n",
    "    config.pe_dim,\n",
    "    config.pegen_dim,\n",
    "    config.sbm_enc_dim,\n",
    "    config.clusters,\n",
    "    config.full_att,\n",
    "    config.checkpoint,\n",
    "    config.max_src_len,\n",
    ")\n",
    "\n",
    "state_path = './csa-trans/outputs/final_models/java_v3/java_v3.pt'\n",
    "state_dict = torch.load(state_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138abe57-dcc7-42c5-8b5c-05898acaa14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb9409a8351466b895dfc73ba9c81e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_pes = []\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(test_loader)):\n",
    "        x, y = _graph_prepare_batch(batch)\n",
    "        y_, sparsity, src_pe, graphs, attns = model(x.to('cuda'))\n",
    "        src_pe = src_pe.detach()\n",
    "        src_pes += src_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4510ecbd-117a-4c6b-bc7e-1aa84b5b9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "input_dim=256\n",
    "hidden_dim=1024\n",
    "device ='cuda'\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ede930d-01d8-451f-a8dd-5049fa2d5287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dfc3bf68da40e3a5d34b7ee561bf08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = [] # the two embeddings\n",
    "Y = [] # intermediate vocabulary\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pes[ast_idx][int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pes[ast_idx][int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        \n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "        \n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e830ac-2b99-4db5-877b-0eba41b5f89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138051\n",
      "34513\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed0b5b2-bdbc-49be-ad71-e51a88d3e79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 12612368\n",
      "Epoch - 0, Accuracy: 0.7125868201255798\n",
      "Epoch - 5, Accuracy: 0.8318576216697693\n",
      "Epoch - 10, Accuracy: 0.8503182530403137\n",
      "Epoch - 15, Accuracy: 0.8592592477798462\n",
      "Epoch - 20, Accuracy: 0.8638599514961243\n",
      "Epoch - 25, Accuracy: 0.8642071485519409\n",
      "Epoch - 30, Accuracy: 0.8642361164093018\n",
      "Epoch - 35, Accuracy: 0.8656249642372131\n",
      "Epoch - 40, Accuracy: 0.8673321604728699\n",
      "Epoch - 45, Accuracy: 0.8692708015441895\n"
     ]
    }
   ],
   "source": [
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        per_sample = loss.item() / BATCH_SIZE\n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d5ced5a-891f-4e0a-8407-3d6b471b8936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b5bb91eb9f418a84eb4b6afb7e04c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 29961\n",
      "Accuracy: 0.8669270873069763\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca362a5-c98a-462a-89f4-63346f389855",
   "metadata": {},
   "source": [
    "## Do the same experiment for Treepos encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c580dfcf-f8ff-4506-8085-5996e00da8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbm_param: 14789888\n",
      "decoder param: 16817152\n",
      "generator param: 10260000\n",
      "Init or load model.\n",
      "Data Set Name : < Fast AST Data Set >\n",
      "loading test data...\n",
      "loading existing dataset\n",
      "dataset lenght: 8714\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(['--config', './config/java_treepos.py', '--g', '0',])\n",
    "config = ConfigObject(args.config)\n",
    "(config.src_vocab,config.tgt_vocab,) = load_vocab(config.data_dir, config.is_split, config.data_type)\n",
    "model = config.model(\n",
    "    config.src_vocab.size(),\n",
    "    config.tgt_vocab.size(),\n",
    "    config.hidden_size,\n",
    "    config.num_heads,\n",
    "    config.num_layers,\n",
    "    config.sbm_layers,\n",
    "    config.use_pegen,\n",
    "    config.dim_feed_forward,\n",
    "    config.dropout,\n",
    "    config.pe_dim,\n",
    "    config.pegen_dim,\n",
    "    config.sbm_enc_dim,\n",
    "    config.clusters,\n",
    "    False,\n",
    "    config.checkpoint,\n",
    "    config.max_src_len,\n",
    ")\n",
    "test_data_set = config.data_set(config, \"test\")\n",
    "test_loader = DataLoader(dataset=test_data_set,batch_size=config.batch_size // len(config.g.split(\",\")),shuffle=False,collate_fn=test_data_set.collect_fn,)\n",
    "state_path = './csa-trans/outputs/final_models/java_v3_treepos/java_v3_treepos.pt'\n",
    "state_dict = torch.load(state_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e389ac0f-ecd7-4846-8831-1e80b068dcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8659fdad4ff843f984e93b059ae85cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_pes = []\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(test_loader)):\n",
    "        x, y = _graph_prepare_batch(batch)\n",
    "        y_, sparsity, src_pe, _, _ = model(x.to('cuda'))\n",
    "        src_pe = src_pe.detach()\n",
    "        src_pes += src_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abb885a9-b157-4c9a-9eec-5d9af0d40463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6438d0e579124360a05ce922acf8bde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = [] # the two embeddings\n",
    "Y = [] # intermediate vocabulary\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pes[ast_idx][int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pes[ast_idx][int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        \n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "        \n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ba7556f-08d2-4137-b729-3367fac1064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 12612368\n",
      "Epoch - 0, Accuracy: 0.4765046238899231\n",
      "Epoch - 5, Accuracy: 0.5166956186294556\n",
      "Epoch - 10, Accuracy: 0.5260995030403137\n",
      "Epoch - 15, Accuracy: 0.5280382037162781\n",
      "Epoch - 20, Accuracy: 0.5299189686775208\n",
      "Epoch - 25, Accuracy: 0.5328414440155029\n",
      "Epoch - 30, Accuracy: 0.5312210321426392\n",
      "Epoch - 35, Accuracy: 0.528211772441864\n",
      "Epoch - 40, Accuracy: 0.5264177918434143\n",
      "Epoch - 45, Accuracy: 0.5288194417953491\n"
     ]
    }
   ],
   "source": [
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        per_sample = loss.item() / BATCH_SIZE\n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92b1e9bc-4dee-4660-a277-93fb57b657f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c936f83f6eae4c068ae84b61076fb073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 18163\n",
      "Accuracy: 0.5255497694015503\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a14642-12dc-4b2c-a792-047e92da6769",
   "metadata": {},
   "source": [
    "## Try with laplacian pe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18788dec-54cd-4891-ae96-d984f85c59c9",
   "metadata": {},
   "source": [
    "### Since laplacian pe and sequential pe are not learnable, they can be just used by changing the configs from treepos configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "381dd434-d001-4c87-a2f5-7b951b8351e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbm_param: 14789888\n",
      "decoder param: 16817152\n",
      "generator param: 10260000\n",
      "Init or load model.\n",
      "Data Set Name : < Fast AST Data Set >\n",
      "loading test data...\n",
      "loading existing dataset\n",
      "dataset lenght: 8714\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(['--config', './config/java_lap.py', '--g', '0',])\n",
    "config = ConfigObject(args.config)\n",
    "(config.src_vocab,config.tgt_vocab,) = load_vocab(config.data_dir, config.is_split, config.data_type)\n",
    "model = config.model(\n",
    "    config.src_vocab.size(),\n",
    "    config.tgt_vocab.size(),\n",
    "    config.hidden_size,\n",
    "    config.num_heads,\n",
    "    config.num_layers,\n",
    "    config.sbm_layers,\n",
    "    config.use_pegen,\n",
    "    config.dim_feed_forward,\n",
    "    config.dropout,\n",
    "    config.pe_dim,\n",
    "    config.pegen_dim,\n",
    "    config.sbm_enc_dim,\n",
    "    config.clusters,\n",
    "    config.full_att,\n",
    "    config.checkpoint,\n",
    "    config.max_src_len,\n",
    ")\n",
    "test_data_set = config.data_set(config, \"test\")\n",
    "test_loader = DataLoader(dataset=test_data_set,batch_size=config.batch_size // len(config.g.split(\",\")),shuffle=False,collate_fn=test_data_set.collect_fn,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da8f4619-f884-42c5-ab38-786a317ab166",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = './csa-trans/outputs/final_models/java_v3_lap/java_v3_lap.pt'\n",
    "state_dict = torch.load(state_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "207e9de8-84f1-4b0b-b31d-2b269022ab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d65f2d802f4d17a1845c9db66e99f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_pes = []\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(test_loader)):\n",
    "        x, y = _graph_prepare_batch(batch)\n",
    "        y_, sparsity, src_pe, _, _ = model(x.to('cuda'))\n",
    "        src_pe = src_pe.detach()\n",
    "        src_pes += src_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "929c4400-07f9-491d-be4a-e6783f185881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15684bdd6b5452fa8bf5a5952eff4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = [] # the two embeddings\n",
    "Y = [] # intermediate vocabulary\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pes[ast_idx][int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pes[ast_idx][int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        \n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "        \n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b55b8129-4dee-498f-ae7a-b638cf462975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 12612368\n",
      "Epoch - 0, Accuracy: 0.24635416269302368\n",
      "Epoch - 5, Accuracy: 0.3444155156612396\n",
      "Epoch - 10, Accuracy: 0.3838252127170563\n",
      "Epoch - 15, Accuracy: 0.3977430462837219\n",
      "Epoch - 20, Accuracy: 0.41197916865348816\n",
      "Epoch - 25, Accuracy: 0.4162904918193817\n",
      "Epoch - 30, Accuracy: 0.4221932888031006\n",
      "Epoch - 35, Accuracy: 0.41495949029922485\n",
      "Epoch - 40, Accuracy: 0.4181423485279083\n",
      "Epoch - 45, Accuracy: 0.4087962806224823\n"
     ]
    }
   ],
   "source": [
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        per_sample = loss.item() / BATCH_SIZE\n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        \n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a719414-b104-4cdb-a9b3-811486a8d703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb69def3fbf34680bdea00e8b15a7c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 14274\n",
      "Accuracy: 0.4130208194255829\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab038631-6f57-4bcc-afb2-543a23247a91",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f9d7b57-dd6e-4693-860f-34b524485dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.components import PositionalEncoding\n",
    "sbm_enc_dim=768\n",
    "src_pe = PositionalEncoding(sbm_enc_dim, config[\"max_src_len\"])\n",
    "src_pe = src_pe.pe.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8fcfa96-f879-4e65-a19e-26bafed87159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bab142c38954cff866122a9a31fa549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = [] # the two embeddings\n",
    "Y = [] # intermediate vocabulary\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pe[int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pe[int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        \n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "        \n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d5a6266-c8da-4265-8d4f-5be424874ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 13923088\n",
      "Epoch - 0, Accuracy: 0.419502317905426\n",
      "Epoch - 5, Accuracy: 0.4334779977798462\n",
      "Epoch - 10, Accuracy: 0.44441550970077515\n",
      "Epoch - 15, Accuracy: 0.4505786895751953\n",
      "Epoch - 20, Accuracy: 0.4515624940395355\n",
      "Epoch - 25, Accuracy: 0.4497685134410858\n",
      "Epoch - 30, Accuracy: 0.4528645873069763\n",
      "Epoch - 35, Accuracy: 0.45315393805503845\n",
      "Epoch - 40, Accuracy: 0.45092591643333435\n",
      "Epoch - 45, Accuracy: 0.45321178436279297\n"
     ]
    }
   ],
   "source": [
    "input_dim=768*2\n",
    "hidden_dim=1024\n",
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "#BATCH_SIZE=64\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        per_sample = loss.item() / BATCH_SIZE\n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30fdc6d5-ea64-459e-903f-63fe0b8c6423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cc9ffe3c644147874071ad5f585235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 15645\n",
      "Accuracy: 0.4526909589767456\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f6a6-c61e-4081-9617-d034280cfdf6",
   "metadata": {},
   "source": [
    "## Triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d6f8db5-8c74-47e0-b3da-34973a929061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbm_param: 14789888\n",
      "decoder param: 16817152\n",
      "generator param: 10260000\n",
      "Init or load model.\n",
      "Data Set Name : < Fast AST Data Set >\n",
      "loading test data...\n",
      "loading existing dataset\n",
      "dataset lenght: 8714\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(['--config', './config/java_triplet.py', '--g', '0',])\n",
    "config = ConfigObject(args.config)\n",
    "(config.src_vocab,config.tgt_vocab,) = load_vocab(config.data_dir, config.is_split, config.data_type)\n",
    "model = config.model(\n",
    "    config.src_vocab.size(),\n",
    "    config.tgt_vocab.size(),\n",
    "    config.hidden_size,\n",
    "    config.num_heads,\n",
    "    config.num_layers,\n",
    "    config.sbm_layers,\n",
    "    config.use_pegen,\n",
    "    config.dim_feed_forward,\n",
    "    config.dropout,\n",
    "    config.pe_dim,\n",
    "    config.pegen_dim,\n",
    "    config.sbm_enc_dim,\n",
    "    config.clusters,\n",
    "    config.full_att,\n",
    "    config.checkpoint,\n",
    "    config.max_src_len,\n",
    ")\n",
    "test_data_set = config.data_set(config, \"test\")\n",
    "test_loader = DataLoader(dataset=test_data_set,batch_size=config.batch_size // len(config.g.split(\",\")),shuffle=False,collate_fn=test_data_set.collect_fn,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04fb4c40-2af3-4e55-8aa2-41eb9f2db7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = './csa-trans/outputs/final_models/java_v3_triplet/java_triplet.pt'\n",
    "state_dict = torch.load(state_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc0b6b96-1d9a-42d9-9bc0-873bc43d01ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2569f7e7fd495489f51ca9654d8368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_pes = []\n",
    "from tqdm.notebook import tqdm\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(test_loader)):\n",
    "        # if idx >= 5:\n",
    "        #     break\n",
    "        x, y = _graph_prepare_batch(batch)\n",
    "        #x.to('cuda')\n",
    "        y_, sparsity, src_pe, _, _ = model(x.to('cuda'))\n",
    "        src_pe = src_pe.detach()\n",
    "        src_pes += src_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eae20595-2813-4246-8cb9-beff9223dd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649a17f2728040289cebf8759235dfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = [] # the two embeddings\n",
    "Y = [] # intermediate vocabulary\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pes[ast_idx][int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pes[ast_idx][int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        \n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "        \n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1e7c882-e769-4c5e-bd3c-85955ed0f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 12612368\n",
      "Epoch - 0, Accuracy: 0.567158579826355\n",
      "Epoch - 5, Accuracy: 0.606336772441864\n",
      "Epoch - 10, Accuracy: 0.6137441992759705\n",
      "Epoch - 15, Accuracy: 0.61328125\n",
      "Epoch - 20, Accuracy: 0.6109374761581421\n",
      "Epoch - 25, Accuracy: 0.6127893328666687\n",
      "Epoch - 30, Accuracy: 0.6154513955116272\n",
      "Epoch - 35, Accuracy: 0.6135995388031006\n",
      "Epoch - 40, Accuracy: 0.6155960559844971\n",
      "Epoch - 45, Accuracy: 0.616348385810852\n"
     ]
    }
   ],
   "source": [
    "input_dim=256\n",
    "hidden_dim=1024\n",
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "#BATCH_SIZE=64\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b6836d4-40c4-4bc6-a875-85310c977b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586336a2cd4d422a97aa97889c61c44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 21303\n",
      "Accuracy: 0.616406261920929\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c905e4-c8e0-48fe-be0d-5b2b1755817b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
