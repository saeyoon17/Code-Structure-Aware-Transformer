{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse general AST using Tree Sitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_utils import dfs_graph\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "from networkx.readwrite import json_graph\n",
    "\n",
    "def init_parser(language):\n",
    "    Language.build_library(\n",
    "        f\"tree_sitter_build/{language}.so\",\n",
    "        [\n",
    "            f\"../../tree_sitter/tree-sitter-{language}\",\n",
    "        ],\n",
    "    )\n",
    "    language = Language(f\"tree_sitter_build/{language}.so\", language)\n",
    "    lang_parser = Parser()\n",
    "    lang_parser.set_language(language)\n",
    "    return lang_parser\n",
    "\n",
    "\n",
    "def clean_code(code):\n",
    "    return (\n",
    "        code.replace(\" DCNL DCSP \", \"\\n\\t\")\n",
    "        .replace(\" DCNL  DCSP \", \"\\n\\t\")\n",
    "        .replace(\" DCNL   DCSP \", \"\\n\\t\")\n",
    "        .replace(\" DCNL \", \"\\n\")\n",
    "        .replace(\" DCSP \", \"\\t\")\n",
    "    )\n",
    "\n",
    "def read_file(file_name):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        return f.readlines()\n",
    "    \n",
    "def get_root(graph):\n",
    "    for node in graph.nodes():\n",
    "        if graph.in_degree(node) == 0:\n",
    "            return node\n",
    "\n",
    "        \n",
    "def generate_pairs(origin_code_file, tp):\n",
    "    origin_code_list = read_file(origin_code_file)\n",
    "    # Use fullset, do not skip\n",
    "    ast_list = []\n",
    "    parser = init_parser('python')\n",
    "    for i, origin_code in tqdm(enumerate(origin_code_list)):\n",
    "        origin_code = clean_code(origin_code)\n",
    "        data_lines = origin_code.splitlines()\n",
    "        # Parse all codes\n",
    "        tree = parser.parse(bytes(origin_code, 'utf-8'))\n",
    "        \n",
    "        cursor = tree.walk()\n",
    "        node_lst = []\n",
    "        language='python'\n",
    "        G = nx.DiGraph()\n",
    "        dfs_graph(origin_code, data_lines, cursor.node, G, 0, node_lst, 0, language)\n",
    "        root = get_root(G)\n",
    "        json_tree = []\n",
    "        json_tree = G2json(G, json_tree, root)\n",
    "        ast_list.append(json.dumps(json_tree, separators=(\",\", \":\"), ensure_ascii=False))\n",
    "    return ast_list\n",
    "\n",
    "# Prune AST based on dangling identifier\n",
    "def prune_ast(G):\n",
    "    keep_node = set()\n",
    "    for e in G.nodes():\n",
    "        if e.split(':')[0] == 'idt':\n",
    "            tmp = e\n",
    "            while len([e for e in G.predecessors(tmp)]) <= 1:\n",
    "                # import ipdb\n",
    "                # ipdb.set_trace()\n",
    "                keep_node.add(tmp)\n",
    "                parents = [e for e in G.predecessors(tmp)]\n",
    "                if len(parents) == 0:\n",
    "                    break\n",
    "                tmp = parents[0]\n",
    "    \n",
    "    original_nodes = set(G.nodes)\n",
    "    remove_nodes = original_nodes - keep_node\n",
    "    G.remove_nodes_from(list(remove_nodes))\n",
    "    return G\n",
    "\n",
    "# if the child's name is same as parent, remove all below the child\n",
    "def prune_ast_remove_redundant(G):\n",
    "    remove_node = set()\n",
    "    for e in G.nodes():\n",
    "        if e.split(':')[0] == 'idt':\n",
    "            node_id = e.split(':')[1]\n",
    "            # if it has parent\n",
    "            if len([e for e in G.predecessors(e)]) == 1:\n",
    "                parent_node = [e for e in G.predecessors(e)][0]\n",
    "                parent_type = parent_node.split(':')[0]\n",
    "                parent_id = parent_node.split(':')[1]\n",
    "                if parent_type == 'nont' and parent_id == node_id:\n",
    "                    remove_node.add(e)\n",
    "                    print(parent_node)\n",
    "                    print(e)\n",
    "                \n",
    "                for child in G.successors(e):\n",
    "                    print(f'remove child - {child}')\n",
    "                    remove_node.add(child)\n",
    "    G.remove_nodes_from(list(remove_node))\n",
    "    return G\n",
    "\n",
    "# if the child's name is same as parent, remove just the child\n",
    "def prune_ast_remove_redundant_strict(G):\n",
    "    remove_node = set()\n",
    "    for e in G.nodes():\n",
    "        if e.split(':')[0] == 'idt':\n",
    "            node_id = e.split(':')[1]\n",
    "            # if it has parent\n",
    "            if len([e for e in G.predecessors(e)]) == 1:\n",
    "                parent_node = [e for e in G.predecessors(e)][0]\n",
    "                parent_type = parent_node.split(':')[0]\n",
    "                parent_id = parent_node.split(':')[1]\n",
    "                if parent_type == 'nont' and parent_id == node_id:\n",
    "                    remove_node.add(e)\n",
    "                    # print(parent_node)\n",
    "                    # print(e)\n",
    "                \n",
    "                if len([e for e in G.successors(e)]) > 0:\n",
    "                    child_node = [e for e in G.successors(e)][0]\n",
    "                    G.add_edge(parent_node, child_node)\n",
    "    G.remove_nodes_from(list(remove_node))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def draw_ast(root_first_seq, color_nodes = []):\n",
    "    G = nx.DiGraph()\n",
    "    n_label_dict = {}\n",
    "    node_colors = []\n",
    "    for idx, node in enumerate(root_first_seq):\n",
    "        n_label_dict[node.label + ':' + str(node.num)] = node.label + ':' + str(node.num)\n",
    "        G.add_node(node.label + ':' + str(node.num))\n",
    "        \n",
    "        \n",
    "        if node.num in color_nodes:\n",
    "            node_colors.append('black')\n",
    "        else:\n",
    "            node_colors.append('white')\n",
    "        \n",
    "        if node.parent != None:\n",
    "            G.add_edge(node.parent.label + ':' + str(node.parent.num), node.label + ':' + str(node.num))\n",
    "    pos = nx.drawing.nx_agraph.graphviz_layout(G, prog='dot')\n",
    "    plt.figure(1, (60, 60))\n",
    "    nx.draw(G, pos, node_color=node_colors, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "def G2json(graph, json_tree, root_node, parent=None, new_idx=0):\n",
    "    json_node = {'children': []}\n",
    "    json_node['label'] = root_node\n",
    "    \n",
    "    if parent != None:\n",
    "        json_node['parent'] = parent['label']\n",
    "        parent['children'].append(json_node['label'])\n",
    "        \n",
    "    json_tree = [json_node]\n",
    "    for child in graph.successors(root_node):\n",
    "        json_tree += G2json(graph, json_tree, child, json_node)\n",
    "    return json_tree\n",
    "\n",
    "# In case pruning may have mismatched the node inexs, we use the function to reorder the labels\n",
    "def reorder_label(json_tree):\n",
    "    idx2idx = {}\n",
    "    # new label assignment for every node\n",
    "    for idx, e in enumerate(json_tree):\n",
    "        old_label = ':'.join(e['label'].split(':')[:-1])\n",
    "        \n",
    "        old_idx = e['label'].split(':')[-1]\n",
    "        new_idx = idx + 1\n",
    "        idx2idx[old_idx] = str(new_idx)\n",
    "        \n",
    "        new_label = old_label + f':{new_idx}'\n",
    "        e['label'] = new_label\n",
    "    \n",
    "    # giving new node ids to children\n",
    "    for e in json_tree:\n",
    "        new_children = []\n",
    "        for child in e['children']:\n",
    "            old_label = ':'.join(child.split(':')[:-1])\n",
    "            old_idx = child.split(':')[-1]\n",
    "            new_idx = idx2idx[old_idx]\n",
    "            new_label = old_label + f':{new_idx}'\n",
    "            new_children.append(new_label)\n",
    "        e['children'] = new_children\n",
    "    return json_tree\n",
    "\n",
    "\n",
    "def save_file(data, file_name):\n",
    "    with open(file_name, \"w\") as f:\n",
    "        for d in data:\n",
    "            if not d.endswith(\"\\n\"):\n",
    "                d = d + \"\\n\"\n",
    "            f.write(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"./py\"\n",
    "out_dir = \"./tree_sitter_python\"\n",
    "data_sets = [\"test\", \"dev\", \"train\"]\n",
    "\n",
    "for data_set in data_sets:\n",
    "    code_file = work_dir + data_set + \"/code.original\"\n",
    "    ast_list = generate_pairs(code_file, data_set)\n",
    "    save_file(ast_list, out_dir + data_set + \"/ast.original\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"./py\"\n",
    "out_dir = \"./tree_sitter_python\"\n",
    "data_sets = [\"test\", \"dev\", \"train\"]\n",
    "for data_set in data_sets:\n",
    "    os.remove(out_dir+data_set + '/nl.original')\n",
    "    shutil.copy(work_dir+data_set+'/javadoc.original', out_dir+data_set+'/nl.original')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
