{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98625ebe-a7ba-4037-be77-b38cdce9e145",
   "metadata": {},
   "source": [
    "# Experiment for RQ2: Intermediate node prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd54b7c-1344-42cb-9ea5-c1ff3648859e",
   "metadata": {},
   "source": [
    "### We first build the dataset for intermediate node prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6353f7b2-c411-4fbc-ace9-f37f9da4a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import load_vocab\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "from py_config_runner import ConfigObject\n",
    "from module import FastASTTrans\n",
    "from ignite.utils import convert_tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eac5893-10ae-4dc0-acef-5fb9f63aa4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c404ebc92284cfb9212f14b1b104457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrices_path = './csa-trans/processed/tree_sitter_python/test/split_matrices.npz'\n",
    "data = np.load(matrices_path, allow_pickle=True)\n",
    "test_rfs = data[\"root_first_seq\"]\n",
    "\n",
    "for split_idx, rfs in enumerate([test_rfs]):\n",
    "    original_test_dataset = {}\n",
    "    for data_idx, sample_ast in enumerate(tqdm(rfs)):\n",
    "        # generate parent_path_list and brother_path_list\n",
    "        distance_map = {}\n",
    "        brother_map = {}\n",
    "\n",
    "        parent_path_list = []\n",
    "        brother_path_list = []\n",
    "\n",
    "        for node in sample_ast:\n",
    "            if len(node.children) == 0:\n",
    "                path = [node.label]\n",
    "                n = node\n",
    "                while n.parent is not None:\n",
    "                    path.append(n.parent.label)\n",
    "                    n = n.parent\n",
    "                parent_path_list.append(list(reversed(path)))\n",
    "            else:\n",
    "                brother_path_list.append([child.label for child in node.children])\n",
    "\n",
    "        # remove identifier dangling nodes from parent path\n",
    "        refined_parent_path_list = []\n",
    "        for path in parent_path_list:\n",
    "            idt_remove_path = []\n",
    "            for e in path:\n",
    "                if e.split(':')[0] != 'idt':\n",
    "                    idt_remove_path.append(e)\n",
    "                else:\n",
    "                    break\n",
    "            if len(idt_remove_path) < 2:\n",
    "                continue\n",
    "            refined_parent_path_list.append(idt_remove_path)\n",
    "\n",
    "        # remove identifier nodes from brother list\n",
    "        refined_brother_path_list = []\n",
    "        for path in brother_path_list:\n",
    "            idt_remove_path = []\n",
    "            for e in path:\n",
    "                if e.split(':')[0] != 'idt':\n",
    "                    idt_remove_path.append(e)\n",
    "            refined_brother_path_list.append(idt_remove_path)\n",
    "\n",
    "        # get dataset\n",
    "        parent_intermediate = set()\n",
    "        brother_intermediate = set()\n",
    "        for par_path in refined_parent_path_list:\n",
    "            for idx in range(len(par_path) - 2):\n",
    "                prev = par_path[idx]\n",
    "                inter = par_path[idx + 1]\n",
    "                after = par_path[idx + 2]\n",
    "                parent_intermediate.add((prev, inter, after))\n",
    "\n",
    "        for bro_path in refined_brother_path_list:\n",
    "            for e in combinations(bro_path, 2):\n",
    "                parent = sample_ast[int(e[0].split(':')[-1]) -1].parent\n",
    "                brother_intermediate.add((e[0], parent.label, e[1]))\n",
    "\n",
    "        parent_intermediate = list(parent_intermediate)\n",
    "        brother_intermediate = list(brother_intermediate)\n",
    "        # sample\n",
    "        SAMPLE_NUM = min([10, len(parent_intermediate), len(brother_intermediate)])\n",
    "        idx1 = np.random.choice(range(len(parent_intermediate)), size=SAMPLE_NUM, replace=False)\n",
    "        idx2 = np.random.choice(range(len(brother_intermediate)), size=SAMPLE_NUM, replace=False)\n",
    "        parent_inter = [parent_intermediate[i] for i in idx1]\n",
    "        brother_inter = [brother_intermediate[i] for i in idx2]\n",
    "        original_test_dataset[data_idx] = parent_inter + brother_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e27d77-065e-40fb-b81f-7768f9257137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _graph_prepare_batch(batch, device=None, non_blocking: bool = False):\n",
    "    x, y = batch\n",
    "    return (\n",
    "        x.to(device),\n",
    "        convert_tensor(y, device=device, non_blocking=non_blocking),\n",
    "    )\n",
    "\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, embeddings, targets):\n",
    "        self.x = embeddings\n",
    "        self.y = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        return x, y\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, indim, hidden, outdim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(indim, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, hidden)\n",
    "        self.fc4 = nn.Linear(hidden, outdim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b241d-330e-48c9-b97a-81dc7261a76b",
   "metadata": {},
   "source": [
    "## Node prediction for CSA-Trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2ed41a6-9bfe-417e-9099-10e09f40c11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Set Name : < Fast AST Data Set >\n",
      "loading test data...\n",
      "loading ./processed/tree_sitter_python/test/split_pot.seq...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18502/18502 [00:04<00:00, 4320.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./processed/tree_sitter_python/test/nl.original ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18502/18502 [00:00<00:00, 306835.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading matrices...\n",
      "building dataset\n",
      "building edges.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18502/18502 [01:27<00:00, 210.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset lenght: 18502\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"Example application\")\n",
    "parser.add_argument(\"--config\", type=Path, help=\"Input configuration file\")\n",
    "parser.add_argument(\"--use_hype_params\", action=\"store_true\")\n",
    "parser.add_argument(\"--data_type\", type=str, default=\"\")\n",
    "parser.add_argument(\"--exp_type\", type=str, default=\"summary\")\n",
    "parser.add_argument(\"--g\", type=str, default=\"\")\n",
    "\n",
    "args = parser.parse_args(['--config', './config/python.py', '--g', '0',])\n",
    "config = ConfigObject(args.config)\n",
    "\n",
    "if args.g != \"\":\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.g\n",
    "    config.device = \"cuda\"\n",
    "    config.g = args.g\n",
    "    \n",
    "(config.src_vocab,config.tgt_vocab,) = load_vocab(config.data_dir, config.is_split, config.data_type)\n",
    "test_data_set = config.data_set(config, \"test\")\n",
    "test_loader = DataLoader(dataset=test_data_set,batch_size=config.batch_size // len(config.g.split(\",\")),shuffle=False,collate_fn=test_data_set.collect_fn,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fdbba64-e33b-488c-8f67-7296cf27d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbm_param: 6777344\n",
      "decoder param: 16817152\n",
      "generator param: 10260000\n",
      "Init or load model.\n"
     ]
    }
   ],
   "source": [
    "model = config.model(\n",
    "    config.src_vocab.size(),\n",
    "    config.tgt_vocab.size(),\n",
    "    config.hidden_size,\n",
    "    config.num_heads,\n",
    "    config.num_layers,\n",
    "    config.sbm_layers,\n",
    "    config.use_pegen,\n",
    "    config.dim_feed_forward,\n",
    "    config.dropout,\n",
    "    config.pe_dim,\n",
    "    config.pegen_dim,\n",
    "    config.sbm_enc_dim,\n",
    "    config.clusters,\n",
    "    config.full_att,\n",
    "    config.checkpoint,\n",
    "    config.max_src_len,\n",
    ")\n",
    "state_path = './csa-trans/outputs/final_models/256_512_512_4_4_10_10_10_b64_tgt50_vanilla/best_model_445_val_bleu=0.3652.pt'\n",
    "state_dict = torch.load(state_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138abe57-dcc7-42c5-8b5c-05898acaa14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bce8da0453f42309c28c37ed0ac91f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_pes = []\n",
    "from tqdm.notebook import tqdm\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(test_loader)):\n",
    "        x, y = _graph_prepare_batch(batch)\n",
    "        y_, sparsity, src_pe, graphs, attns = model(x.to('cuda'))\n",
    "        src_pe = src_pe.detach()\n",
    "        src_pes += src_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64db7d2a-8a5b-46b6-846c-7d836d8f0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "input_dim=512\n",
    "hidden_dim=1024\n",
    "device ='cuda'\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ede930d-01d8-451f-a8dd-5049fa2d5287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e746dcfba2443c083099c716d54428a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = [] # the two embeddings\n",
    "Y = [] # intermediate vocabulary\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pes[ast_idx][int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pes[ast_idx][int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        \n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "442f054d-4442-4a97-a0cd-270318c11893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293814\n",
      "73454\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ed0b5b2-bdbc-49be-ad71-e51a88d3e79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 12874512\n",
      "Epoch - 0, Accuracy: 0.8217688202857971\n",
      "Epoch - 5, Accuracy: 0.8769599199295044\n",
      "Epoch - 10, Accuracy: 0.8866643309593201\n",
      "Epoch - 15, Accuracy: 0.8973486423492432\n",
      "Epoch - 20, Accuracy: 0.8905161023139954\n",
      "Epoch - 25, Accuracy: 0.892271876335144\n",
      "Epoch - 30, Accuracy: 0.8931974172592163\n",
      "Epoch - 35, Accuracy: 0.8904889225959778\n",
      "Epoch - 40, Accuracy: 0.8949259519577026\n",
      "Epoch - 45, Accuracy: 0.8969947695732117\n"
     ]
    }
   ],
   "source": [
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d5ced5a-891f-4e0a-8407-3d6b471b8936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e307f12c003349608581024e5712a0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 65822\n",
      "Accuracy: 0.8958787322044373\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca362a5-c98a-462a-89f4-63346f389855",
   "metadata": {},
   "source": [
    "## Treepos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c580dfcf-f8ff-4506-8085-5996e00da8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbm_param: 6777344\n",
      "decoder param: 16817152\n",
      "generator param: 10260000\n",
      "Init or load model.\n",
      "Data Set Name : < Fast AST Data Set >\n",
      "loading test data...\n",
      "loading existing dataset\n",
      "dataset lenght: 18502\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(['--config', './config/python_treepos.py', '--g', '0',])\n",
    "config = ConfigObject(args.config)\n",
    "(config.src_vocab,config.tgt_vocab,) = load_vocab(config.data_dir, config.is_split, config.data_type)\n",
    "model = config.model(\n",
    "    config.src_vocab.size(),\n",
    "    config.tgt_vocab.size(),\n",
    "    config.hidden_size,\n",
    "    config.num_heads,\n",
    "    config.num_layers,\n",
    "    config.sbm_layers,\n",
    "    config.use_pegen,\n",
    "    config.dim_feed_forward,\n",
    "    config.dropout,\n",
    "    config.pe_dim,\n",
    "    config.pegen_dim,\n",
    "    config.sbm_enc_dim,\n",
    "    config.clusters,\n",
    "    config.full_att,\n",
    "    config.checkpoint,\n",
    "    config.max_src_len,\n",
    ")\n",
    "test_data_set = config.data_set(config, \"test\")\n",
    "test_loader = DataLoader(dataset=test_data_set,batch_size=config.batch_size // len(config.g.split(\",\")),shuffle=False,collate_fn=test_data_set.collect_fn,)\n",
    "state_path = './csa-trans/outputs/final_models/python_v3_treepos/best_model_495_val_bleu=0.3628.pt'\n",
    "state_dict = torch.load(state_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e389ac0f-ecd7-4846-8831-1e80b068dcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4accef28ce8546b9a80247d1558e8cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_pes = []\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(test_loader)):\n",
    "        x, y = _graph_prepare_batch(batch)\n",
    "        y_, sparsity, src_pe, _, _ = model(x.to('cuda'))\n",
    "        src_pe = src_pe.detach()\n",
    "        src_pes += src_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abb885a9-b157-4c9a-9eec-5d9af0d40463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd13e58cbc84e71b4d765b085983a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = []\n",
    "Y = []\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pes[ast_idx][int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pes[ast_idx][int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        \n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "        \n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ba7556f-08d2-4137-b729-3367fac1064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 12874512\n",
      "Epoch - 0, Accuracy: 0.6163436770439148\n",
      "Epoch - 5, Accuracy: 0.6502476930618286\n",
      "Epoch - 10, Accuracy: 0.6522485017776489\n",
      "Epoch - 15, Accuracy: 0.651921808719635\n",
      "Epoch - 20, Accuracy: 0.6494311094284058\n",
      "Epoch - 25, Accuracy: 0.649567186832428\n",
      "Epoch - 30, Accuracy: 0.649703323841095\n",
      "Epoch - 35, Accuracy: 0.6477161645889282\n",
      "Epoch - 40, Accuracy: 0.648015558719635\n",
      "Epoch - 45, Accuracy: 0.6464503407478333\n"
     ]
    }
   ],
   "source": [
    "device ='cuda'\n",
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92b1e9bc-4dee-4660-a277-93fb57b657f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbdf585ce5d4949af955133de6d78b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 47571\n",
      "Accuracy: 0.6474711298942566\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a14642-12dc-4b2c-a792-047e92da6769",
   "metadata": {},
   "source": [
    "## Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18788dec-54cd-4891-ae96-d984f85c59c9",
   "metadata": {},
   "source": [
    "### Since laplacian pe and sequential pe are not learnable, they can be just used by changing the configs from treepos configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "381dd434-d001-4c87-a2f5-7b951b8351e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbm_param: 6777344\n",
      "decoder param: 16817152\n",
      "generator param: 10260000\n",
      "Init or load model.\n",
      "Data Set Name : < Fast AST Data Set >\n",
      "loading test data...\n",
      "loading existing dataset\n",
      "dataset lenght: 18502\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(['--config', './config/python_lap.py', '--g', '0',])\n",
    "config = ConfigObject(args.config)\n",
    "(config.src_vocab,config.tgt_vocab,) = load_vocab(config.data_dir, config.is_split, config.data_type)\n",
    "model = config.model(\n",
    "    config.src_vocab.size(),\n",
    "    config.tgt_vocab.size(),\n",
    "    config.hidden_size,\n",
    "    config.num_heads,\n",
    "    config.num_layers,\n",
    "    config.sbm_layers,\n",
    "    config.use_pegen,\n",
    "    config.dim_feed_forward,\n",
    "    config.dropout,\n",
    "    config.pe_dim,\n",
    "    config.pegen_dim,\n",
    "    config.sbm_enc_dim,\n",
    "    config.clusters,\n",
    "    config.full_att,\n",
    "    config.checkpoint,\n",
    "    config.max_src_len,\n",
    ")\n",
    "test_data_set = config.data_set(config, \"test\")\n",
    "test_loader = DataLoader(dataset=test_data_set,batch_size=config.batch_size // len(config.g.split(\",\")),shuffle=False,collate_fn=test_data_set.collect_fn,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da8f4619-f884-42c5-ab38-786a317ab166",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = './csa-trans/outputs/final_models/python_v3_lap/best_model_470_val_bleu=0.3542.pt'\n",
    "state_dict = torch.load(state_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "207e9de8-84f1-4b0b-b31d-2b269022ab9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c39091ff6074d16bdc182ee30cba277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_pes = []\n",
    "from tqdm.notebook import tqdm\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(test_loader)):\n",
    "        x, y = _graph_prepare_batch(batch)\n",
    "        y_, sparsity, src_pe, _, _ = model(x.to('cuda'))\n",
    "        src_pe = src_pe.detach()\n",
    "        src_pes += src_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "929c4400-07f9-491d-be4a-e6783f185881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f14b5fd66146e7aa2a50125b617c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = [] # the two embeddings\n",
    "Y = [] # intermediate vocabulary\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pes[ast_idx][int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pes[ast_idx][int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        \n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "        \n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b55b8129-4dee-498f-ae7a-b638cf462975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 12874512\n",
      "Epoch - 0, Accuracy: 0.2962352931499481\n",
      "Epoch - 5, Accuracy: 0.38283973932266235\n",
      "Epoch - 10, Accuracy: 0.4082643687725067\n",
      "Epoch - 15, Accuracy: 0.43522703647613525\n",
      "Epoch - 20, Accuracy: 0.44885125756263733\n",
      "Epoch - 25, Accuracy: 0.45135563611984253\n",
      "Epoch - 30, Accuracy: 0.4589911997318268\n",
      "Epoch - 35, Accuracy: 0.45531630516052246\n",
      "Epoch - 40, Accuracy: 0.4538191556930542\n",
      "Epoch - 45, Accuracy: 0.46235302090644836\n"
     ]
    }
   ],
   "source": [
    "device ='cuda'\n",
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a719414-b104-4cdb-a9b3-811486a8d703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33454738d5ff485c87cc46d9ae51b52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 33482\n",
      "Accuracy: 0.4557110369205475\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab038631-6f57-4bcc-afb2-543a23247a91",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f9d7b57-dd6e-4693-860f-34b524485dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.components import PositionalEncoding\n",
    "sbm_enc_dim=512\n",
    "src_pe = PositionalEncoding(sbm_enc_dim, config[\"max_src_len\"])\n",
    "src_pe = src_pe.pe.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8fcfa96-f879-4e65-a19e-26bafed87159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02813c43fbfa47f0a904b91b49877b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = [] # the two embeddings\n",
    "Y = [] # intermediate vocabulary\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pe[int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pe[int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "        \n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d5a6266-c8da-4265-8d4f-5be424874ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 13398800\n",
      "Epoch - 0, Accuracy: 0.36192017793655396\n",
      "Epoch - 5, Accuracy: 0.36646613478660583\n",
      "Epoch - 10, Accuracy: 0.3715973496437073\n",
      "Epoch - 15, Accuracy: 0.3741697669029236\n",
      "Epoch - 20, Accuracy: 0.3732578456401825\n",
      "Epoch - 25, Accuracy: 0.3739519715309143\n",
      "Epoch - 30, Accuracy: 0.37321701645851135\n",
      "Epoch - 35, Accuracy: 0.37287673354148865\n",
      "Epoch - 40, Accuracy: 0.37434670329093933\n",
      "Epoch - 45, Accuracy: 0.37412893772125244\n"
     ]
    }
   ],
   "source": [
    "input_dim=1024\n",
    "hidden_dim=1024\n",
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        per_sample = loss.item() / BATCH_SIZE\n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        \n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30fdc6d5-ea64-459e-903f-63fe0b8c6423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c20b3140854196a18fc2838f844638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 27450\n",
      "Accuracy: 0.373611718416214\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f6a6-c61e-4081-9617-d034280cfdf6",
   "metadata": {},
   "source": [
    "## Triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d6f8db5-8c74-47e0-b3da-34973a929061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sbm_param: 6777344\n",
      "decoder param: 16817152\n",
      "generator param: 10260000\n",
      "Init or load model.\n",
      "Data Set Name : < Fast AST Data Set >\n",
      "loading test data...\n",
      "loading existing dataset\n",
      "dataset lenght: 18502\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(['--config', './config/python_triplet.py', '--g', '0',])\n",
    "config = ConfigObject(args.config)\n",
    "(config.src_vocab,config.tgt_vocab,) = load_vocab(config.data_dir, config.is_split, config.data_type)\n",
    "model = config.model(\n",
    "    config.src_vocab.size(),\n",
    "    config.tgt_vocab.size(),\n",
    "    config.hidden_size,\n",
    "    config.num_heads,\n",
    "    config.num_layers,\n",
    "    config.sbm_layers,\n",
    "    config.use_pegen,\n",
    "    config.dim_feed_forward,\n",
    "    config.dropout,\n",
    "    config.pe_dim,\n",
    "    config.pegen_dim,\n",
    "    config.sbm_enc_dim,\n",
    "    config.clusters,\n",
    "    config.full_att,\n",
    "    config.checkpoint,\n",
    "    config.max_src_len,\n",
    ")\n",
    "test_data_set = config.data_set(config, \"test\")\n",
    "test_loader = DataLoader(dataset=test_data_set,batch_size=config.batch_size // len(config.g.split(\",\")),shuffle=False,collate_fn=test_data_set.collect_fn,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04fb4c40-2af3-4e55-8aa2-41eb9f2db7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = '/home/coinse/greentea/src/cbcgt/outputs/final_models/python_v3_triplet/python_triplet.pt'\n",
    "state_dict = torch.load(state_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f13c2ccf-7dc8-4be9-8c81-db2b7e793299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca5bcf683694feba5fc13964c0453b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_pes = []\n",
    "with torch.no_grad():\n",
    "    for idx, batch in tqdm(enumerate(test_loader)):\n",
    "        # if idx >= 5:\n",
    "        #     break\n",
    "        x, y = _graph_prepare_batch(batch)\n",
    "        y_, sparsity, src_pe, _, _ = model(x.to('cuda'))\n",
    "        src_pe = src_pe.detach()\n",
    "        src_pes += src_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e305802e-4c31-476f-8b0c-2a50246e0239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdb4bdbbf1147ca993a1394a3d838bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "whole = list(original_test_dataset.values())\n",
    "X = [] # the two embeddings\n",
    "Y = [] # intermediate vocabulary\n",
    "for ast_idx, ast_instance in tqdm(enumerate(whole)):\n",
    "    for path in ast_instance:\n",
    "        node1 = src_pes[ast_idx][int(path[0].split(':')[-1]) - 1]\n",
    "        node2 = src_pes[ast_idx][int(path[2].split(':')[-1]) - 1]\n",
    "\n",
    "        if path[1].split(':')[1] not in config.src_vocab.w2i.keys():\n",
    "            continue\n",
    "        tgt = config.src_vocab.w2i[path[1].split(':')[1]]\n",
    "        \n",
    "        X.append(torch.cat([node1, node2]))\n",
    "        Y.append(tgt)\n",
    "        \n",
    "train_X = X[:int(len(X)*0.8)]\n",
    "train_Y = Y[:int(len(X)*0.8)]\n",
    "test_X = X[int(len(X)*0.8):]\n",
    "test_Y = Y[int(len(X)*0.8):]\n",
    "train_dataset = SyntheticDataset(train_X, train_Y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataset = SyntheticDataset(test_X, test_Y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94ff7b10-f4a8-4b9b-bba5-71481cabedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_param: 12874512\n",
      "Epoch - 0, Accuracy: 0.5974248647689819\n",
      "Epoch - 5, Accuracy: 0.6176366806030273\n",
      "Epoch - 10, Accuracy: 0.6222915053367615\n",
      "Epoch - 15, Accuracy: 0.6238430738449097\n",
      "Epoch - 20, Accuracy: 0.6251769661903381\n",
      "Epoch - 25, Accuracy: 0.6228495240211487\n",
      "Epoch - 30, Accuracy: 0.6257485747337341\n",
      "Epoch - 35, Accuracy: 0.626415491104126\n",
      "Epoch - 40, Accuracy: 0.6255171895027161\n",
      "Epoch - 45, Accuracy: 0.6257213950157166\n"
     ]
    }
   ],
   "source": [
    "input_dim=512\n",
    "hidden_dim=1024\n",
    "out_dim=config.src_vocab.size()\n",
    "model = MLP(input_dim, hidden_dim, out_dim)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "num_param = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"num_param: {num_param}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    loss_acc = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x.to(device))\n",
    "        loss = criterion(pred, y.to(device).squeeze())\n",
    "        loss.backward()\n",
    "        loss_acc += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if epoch%5 == 0:\n",
    "        per_sample = loss_acc / len(train_loader) / BATCH_SIZE\n",
    "        total_correct = 0\n",
    "        model.eval()\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            pred = model(x.to(device))\n",
    "            total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "        print(f'Epoch - {epoch}, Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da9f1cde-27b2-45e8-84bd-fffbe6864497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426c482e64b94f05988b94583140e6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/574 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correct: 45896\n",
      "Accuracy: 0.6246733665466309\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "model.eval()\n",
    "for batch in tqdm(test_loader):\n",
    "    x, y = batch\n",
    "    pred = model(x.to(device))\n",
    "    total_correct += torch.sum(torch.argmax(pred, dim=-1) == y.squeeze().to('cuda'))\n",
    "print(f'Total correct: {total_correct}')\n",
    "print(f'Accuracy: {total_correct / len(test_loader) / BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a0f97-8944-4503-8917-1197824ea71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db40f3-2e93-40fa-befa-84006484c581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
